{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./local_data/df_final_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = data.filter(data.select_dtypes([\"float64\", \"int64\"]).columns)\n",
    "numerical_data = numerical_data.fillna(numerical_data.median()).dropna(axis=1)\n",
    "drop_cols = [\n",
    "    \"id\",\n",
    "    \"host_id\",\n",
    "    \"name\",\n",
    "    \"neighbourhood_group\",\n",
    "    \"neighbourhood\",\n",
    "    \"last_review\",\n",
    "    \"scrape_id\",\n",
    "    \"price_per_person\",\n",
    "]\n",
    "numerical_data = numerical_data.drop(\n",
    "    columns=drop_cols, errors=\"ignore\"\n",
    ")  # ohne outliers\n",
    "# numerical_data = numerical_data[\n",
    "#     numerical_data[\"price\"] < numerical_data[\"price\"].quantile(0.99)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    transformed_df = df.copy()\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "    if \"price\" in numeric_cols:\n",
    "        numeric_cols.remove(\"price\")\n",
    "\n",
    "    sqrt_df = df[numeric_cols].apply(lambda x: np.sqrt(x - x.min() + 1))\n",
    "    sqrt_df.columns = [f\"sqrt_{col}\" for col in numeric_cols]\n",
    "\n",
    "    log_df = df[numeric_cols].apply(lambda x: np.log(x - x.min() + 1))\n",
    "    log_df.columns = [f\"log_{col}\" for col in numeric_cols]\n",
    "\n",
    "    # winsorisation\n",
    "    wins_df = df[numeric_cols].apply(\n",
    "        lambda x: stats.mstats.winsorize(x, limits=[0.023, 0.023])\n",
    "    )\n",
    "    wins_df.columns = [f\"wins_{col}\" for col in numeric_cols]\n",
    "\n",
    "    return pd.concat([transformed_df, sqrt_df, log_df, wins_df], axis=1)\n",
    "\n",
    "\n",
    "numerical_data_transformed = transform_features(numerical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_data_transformed.drop(\"price\", axis=1)\n",
    "y = numerical_data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data_transformed.sort_values(\"price\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=99\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(100, 500),\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\": randint(1, 10),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    random_state=99,\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# # Define a distribution of parameters to sample from\n",
    "# param_distributions = {\n",
    "#     # Continuous range for max_features using uniform distribution\n",
    "#     'max_features': uniform(0.1, 1.0),\n",
    "\n",
    "#     # Integer range for number of estimators\n",
    "#     'n_estimators': randint(50, 500),\n",
    "\n",
    "#     # Continuous range for minimum samples split\n",
    "#     'min_samples_split': uniform(0.1, 0.9),\n",
    "\n",
    "#     # Continuous range for minimum samples leaf\n",
    "#     'min_samples_leaf': uniform(0.01, 0.2),\n",
    "\n",
    "#     # Maximum depth with more nuanced sampling\n",
    "#     'max_depth': [None] + list(randint(10, 50).rvs(10))\n",
    "# }\n",
    "\n",
    "# # Create a base random forest regressor\n",
    "# rf = RandomForestRegressor(random_state=99)\n",
    "\n",
    "# # Perform randomized search with cross-validation\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_distributions=param_distributions,\n",
    "#     n_iter=100,  # Number of parameter settings that are sampled\n",
    "#     cv=5,  # 5-fold cross-validation\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     verbose=2,  # Show progress\n",
    "#     random_state=42,  # For reproducibility\n",
    "#     scoring='neg_mean_squared_error'  # Optimization metric\n",
    "# )\n",
    "\n",
    "# # Fit the randomized search to the data\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# # Get the best estimator\n",
    "# best_rf = random_search.best_estimator_\n",
    "\n",
    "# # Evaluate the best model\n",
    "# train_score = best_rf.score(X_train, y_train)\n",
    "# test_score = best_rf.score(X_test, y_test)\n",
    "\n",
    "# print(f\"Train R² Score: {train_score:.4f}\")\n",
    "# print(f\"Test R² Score: {test_score:.4f}\")\n",
    "\n",
    "# # Optional: Inspect the results\n",
    "# results = random_search.cv_results_\n",
    "# for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "#     print(f\"Mean Score: {-mean_score:.4f}, Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id, accomodates, bathrooms, beds, bedrooms, noise night, noise day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "\n",
    "def perform_rf(X_train_scaled, y_train):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=297,\n",
    "        random_state=99,\n",
    "        max_depth=None,\n",
    "        min_samples_split=6,\n",
    "        min_samples_leaf=3,\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    return rf\n",
    "\n",
    "\n",
    "def evaluate_rf(rf, y_true, y_pred, dataset_name: str):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{dataset_name} Metrics:\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X.columns, \"importance\": rf.feature_importances_}\n",
    "    ).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"feature_importance\": feature_importance,\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_rf_performance(y_true, y_pred, feature_importance):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "    # Scatter, actual vs predicted\n",
    "    axes[0].scatter(y_true, y_pred, alpha=0.5)\n",
    "    axes[0].plot(\n",
    "        [y_true.min(), y_true.max()], [y_true.min(), y_true.max()], \"r--\", lw=2\n",
    "    )\n",
    "    axes[0].set_title(\"Actual vs Predicted Values\")\n",
    "    axes[0].set_xlabel(\"Actual Values\")\n",
    "    axes[0].set_ylabel(\"Predicted Values\")\n",
    "\n",
    "    # feature_importance bar chart (top 10)\n",
    "\n",
    "    top_features = feature_importance.head(10)\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=top_features, ax=axes[1])\n",
    "    axes[1].set_title(\"Top 10 Most Important Features\")\n",
    "    axes[1].set_xlabel(\"Feature Importance\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "rf = perform_rf(X_train_scaled, y_train)  # fit random forest model\n",
    "\n",
    "y_train_pred_rf = rf.predict(X_train_scaled)  # make predictions\n",
    "y_test_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "dict_rf1 = evaluate_rf(\n",
    "    rf, y_train, y_train_pred_rf, \"train\"\n",
    ")  # evaluate with MSE etc. and show most important features\n",
    "\n",
    "mse1, rmse1, mae1, r21, feature_importance1 = evaluate_rf(\n",
    "    rf, y_test, y_test_pred_rf, \"test\"\n",
    ")\n",
    "\n",
    "visualize_rf_performance(\n",
    "    y_train, y_train_pred_rf, dict_rf1[\"feature_importance\"]\n",
    ")  # create scatter plot with actual vs predicted data, plot bar chart with most important features, or use Y_TEST_PRED_RF TO VISUALISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(\n",
    "    cv=cv,\n",
    "    random_state=99,\n",
    "    max_iter=100000,\n",
    "    alphas=np.logspace(-2, 3, 100),\n",
    "    selection=\"random\",\n",
    "    tol=1e-3,\n",
    "    fit_intercept=True,\n",
    ")\n",
    "\n",
    "lasso_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.plot(\n",
    "    lasso_cv.alphas_,\n",
    "    lasso_cv.mse_path_.mean(axis=1),\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    alpha=0.7,\n",
    "    label=\"Cross-validation Scores\",\n",
    ")\n",
    "# Plot the final chosen regularization parameter\n",
    "ax.vlines(\n",
    "    lasso_cv.alpha_,\n",
    "    0,\n",
    "    ax.get_ylim()[1],\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    "    label=r\"Best $\\lambda$\",\n",
    ")\n",
    "\n",
    "# Aesthetics\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Regularization parameter\")\n",
    "ax.set_ylabel(\"Mean Squared Error\")\n",
    "ax.set_title(r\"Lasso Cross-validation Score as a Function of $\\lambda$\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "print(f\"Best regularization parameter: {lasso_cv.alpha_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray, dataset_name: str) -> None:\n",
    "    \"\"\"\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "\n",
    "y_train_pred = lasso_cv.predict(X_train_scaled)\n",
    "y_test_pred = lasso_cv.predict(X_test_scaled)\n",
    "\n",
    "evaluate_model(y_train, y_train_pred, \"train\")\n",
    "evaluate_model(y_test, y_test_pred, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"feat\": X.columns, \"coeff\": lasso_cv.coef_})\n",
    "\n",
    "feature_importance[\"Abs_coeff\"] = abs(feature_importance[\"coeff\"])\n",
    "feature_importance_sorted = feature_importance.sort_values(\"Abs_coeff\", ascending=False)\n",
    "non_zero_features = feature_importance_sorted[feature_importance_sorted[\"coeff\"] != 0]\n",
    "\n",
    "print(r\"\\coeffs:\")\n",
    "print(non_zero_features[[\"feat\", \"coeff\"]].to_string())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\", lw=2)\n",
    "plt.xlabel(\"Actual y\")\n",
    "plt.ylabel(\"Pred y\")\n",
    "plt.title(\"Actual vs Pred ys (test)\")\n",
    "\n",
    "# Plot 2: feat coeffs\n",
    "plt.subplot(1, 2, 2)\n",
    "non_zero_features.plot(kind=\"bar\", x=\"feat\", y=\"coeff\", ax=plt.gca())\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"coeffs\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"residuals distribuvition\")\n",
    "plt.xlabel(\"resid val\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Pred y\")\n",
    "plt.ylabel(\"resid\")\n",
    "plt.title(\"resids vs Pred values\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_df = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X.columns,\n",
    "        \"coeff\": lasso_cv.coef_,\n",
    "        \"coeff_abs\": abs(lasso_cv.coef_),\n",
    "    }\n",
    ")\n",
    "\n",
    "coefficient_df = coefficient_df.sort_values(\"coeff_abs\", ascending=False)\n",
    "coefficient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
